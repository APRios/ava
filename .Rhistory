length(link)
lis[1:3]
link.raw<-sapply(lis, xmlGetAttr,"//a", "href")
link<-unlist(link.raw)
length(link)
link[1:3]
link
link.raw<-sapply(lis,"//a[@href]", xmlGetAttr, "href")
link<-unlist(link.raw)
link.raw<-xpathApply(lis,"//a[@href]", xmlGetAttr, "href")
link.raw<-xpathApply(lis[[1]],"//a[@href]", xmlGetAttr, "href")
link<-unlist(link.raw)
link
link[1:3]
link.raw<-spply(lis[[1]], xmlGetAttr,"//a[@href]", "href")
link.raw<-sapply(lis[[1]], xmlGetAttr,"//a[@href]", "href")
link.raw<-sapply(lis, xmlGetAttr,"//a[@href]", "href")
link<-unlist(link.raw)
length(link)
link
link.raw<-sapply(lis, xmlGetAttr, "href","//a[@href]")
link<-unlist(link.raw)
link
link.raw<-sapply(lis, xmlGetAttr, "//a[@href]")
link<-unlist(link.raw)
link
link.raw<-sapply(lis, xmlGetAttr, "href")
link<-unlist(link.raw)
link
link.raw<-sapply(lis, xmlGetAttr,"//a[@href]", "href")
link<-unlist(link.raw)
link[1:3]
link.raw<-sapply(lis,"//a[@href]", xmlGetAttr, "href")
link<-unlist(link.raw)
link.raw<-sapply(lis, xmlGetAttr,"//a[@href]", "href")
link<-unlist(link.raw)
link[1:3]
link.raw<-sapply(lis,"//a[@href]", xmlGetAttr)
link.raw<-sapply(lis, xmlGetAttr, "//a[@href]")
link<-unlist(link.raw)
link
lis<-getNodeSet(raw.html, "//div[@class='linkdesc']//..")
link.raw<-sapply(lis, xmlGetAttr, "//a[@href]")
link<-unlist(link.raw)
link
lis[1:3]
link.raw<-sapply(lis, xmlValue, "//a[@href]")
link<-unlist(link.raw)
link
?xmlGetAttr
as<-getNodeSet(lis[[1]], "//a")
link.raw<-sapply(as, xmlGetAttr, "//a[@href]")
link<-unlist(link.raw)
link
link.raw<-sapply(as, xmlGetAttr, "href")
link<-unlist(link.raw)
link
link[1,3]
link[1:3]
as[1:3]
lis[1:3]
as<-sapply(lis, getNodeSet, "//a")
as[1:3]
lis[[1]]
link[1]
lis[[4]]
as[1:3]
test<-sapply(lis, xmlGetAttr, "//a[@href")
test
test<-sapply(lis, xmlGetAttr, "href")
test
test<-sapply(lis, xmlGetAttr, "//a", href")
#Get Link Text
link.text.raw<-sapply(lis, xmlValue, "//a")
link.text<-unlist(link.text.raw)
test<-data.frame(link, link.text, stringsAsFactors = FALSE)
#Get Link Description
link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc.text<-sapply(link.desc, xmlValue)
test<-sapply(lis, xmlGetAttr, "//a", href")
#Get Link Text
link.text.raw<-sapply(lis, xmlValue, "//a")
link.text<-unlist(link.text.raw)
test<-data.frame(link, link.text, stringsAsFactors = FALSE)
#Get Link Description
link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc.text<-sapply(link.desc, xmlValue)
test<-sapply(lis, xmlGetAttr, "//a", href")
#Get Link Text
link.text.raw<-sapply(lis, xmlValue, "//a")
link.text<-unlist(link.text.raw)
test<-data.frame(link, link.text, stringsAsFactors = FALSE)
#Get Link Description
link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc.text<-sapply(link.desc, xmlValue)
test<-sapply(lis, xmlGetAttr, "//a", "href")
test
test<-getNodeSet(raw.html, "//div[@class='linkdesc']//..//a")
test
test[1]
as<-getNodeSet(raw.html, "//div[@class='linkdesc']//..//a")
#as<-sapply(lis, getNodeSet, "//a")
link.raw<-sapply(as, xmlGetAttr, "href")
link<-unlist(link.raw)
link
link[1:3]
link.text.raw<-sapply(as, xmlValue, "//a")
link.text<-unlist(link.text.raw)
length(link.text)
as<-getNodeSet(raw.html, "//div[@class='linkdesc']//..//div")
link.desc.text<-sapply(link.desc, xmlValue)
link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']//..//div")
link.desc.text<-sapply(link.desc, xmlValue)
length(link.desc.text)
link.desc.text[1:3]
link.desc.text[199:201]
link[200]
link[199:200]
link[197:200]
link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc.text<-sapply(link.desc, xmlValue)
length(link.desc.text)
link.desc.text<-unlist(link.desc.text)
length(link.desc.text)
dftest<-data.frame(link, link.text, stringsAsFactors = FALSE)
head(dftest)
link.desc[1:3]
link.desc[4:6]
link.desc.text
dftest<-data.frame(link, link.text, link.desc.text, stringsAsFactors = FALSE)
dftest<-data.frame(link, link.text, link.desc.text[1:200], stringsAsFactors = FALSE)
write.csv(dftest, file="")
write.csv(dftest, file="C:\\Users\\mmtobias\\Documents\\Website\\Links.csv")
#PURPOSE: Scrape the links and link descriptions from the old Map & GIS LibGuide
# http://guides.lib.ucdavis.edu/Maps_GIS
# Reference: http://dsi.ucdavis.edu/ClimateRefuge/
# Reference: http://datascience.ucdavis.edu/NSFWorkshops/WebScraping/ScheduleOutline.html
# Regex Builder: http://regexr.com/
#Load Libraries
library(XML)
library(RCurl)
#Where to save the CSV of links and what to call it
#SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\Links.csv"
SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\MapsOnline.csv"
#The target website
#LibGuide = "http://guides.lib.ucdavis.edu/Maps_GIS"
LibGuide = "http://guides.lib.ucdavis.edu/Maps_Online"
#Download website to a file
#getHTMLLinks(LibGuide)
raw.html<-htmlTreeParse(LibGuide, useInternalNodes=T)
#Parse HTML
#Stuff that didn't work:
#link.text<-xpathSApply(raw.html, "//a", xmlValue)
#uls<-xpathSApply(raw.html, "//li", xmlValue)
#uls<-getNodeSet(raw.html, "//li|//a/@href")
#Get the nodes that are unordered list items <li>
#lis<-getNodeSet(raw.html, "//li")
lis<-getNodeSet(raw.html, "//div[@class='linkdesc']//..")
#Get Links
#as<-getNodeSet(lis[[1]], "//a")
as<-getNodeSet(raw.html, "//div[@class='linkdesc']//..//a")
#as<-sapply(lis, getNodeSet, "//a")
link.raw<-sapply(as, xmlGetAttr, "href")
link<-unlist(link.raw)
#Get Link Text
link.text.raw<-sapply(as, xmlValue, "//a")
link.text<-unlist(link.text.raw)
#Get Link Description
#link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc.text<-sapply(link.desc, xmlValue)
link.desc.text<-unlist(link.desc.text)
dftest<-data.frame(link, link.text, link.desc.text[1:200], stringsAsFactors = FALSE)
write.csv(dftest, file=SaveFileAs)
#PURPOSE: Scrape the links and link descriptions from the old Map & GIS LibGuide
# http://guides.lib.ucdavis.edu/Maps_GIS
# Reference: http://dsi.ucdavis.edu/ClimateRefuge/
# Reference: http://datascience.ucdavis.edu/NSFWorkshops/WebScraping/ScheduleOutline.html
# Regex Builder: http://regexr.com/
#Load Libraries
library(XML)
library(RCurl)
#Where to save the CSV of links and what to call it
#SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\Links.csv"
SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\MapsOnline.csv"
#The target website
#LibGuide = "http://guides.lib.ucdavis.edu/Maps_GIS"
LibGuide = "http://guides.lib.ucdavis.edu/Maps_Online"
#Download website to a file
#getHTMLLinks(LibGuide)
raw.html<-htmlTreeParse(LibGuide, useInternalNodes=T)
#Parse HTML
#Stuff that didn't work:
#link.text<-xpathSApply(raw.html, "//a", xmlValue)
#uls<-xpathSApply(raw.html, "//li", xmlValue)
#uls<-getNodeSet(raw.html, "//li|//a/@href")
#Get the nodes that are unordered list items <li>
#lis<-getNodeSet(raw.html, "//li")
lis<-getNodeSet(raw.html, "//div[@class='linkdesc']//..")
#Get Links
#as<-getNodeSet(lis[[1]], "//a")
as<-getNodeSet(raw.html, "//div[@class='linkdesc']//..//a")
#as<-sapply(lis, getNodeSet, "//a")
link.raw<-sapply(as, xmlGetAttr, "href")
link<-unlist(link.raw)
#Get Link Text
link.text.raw<-sapply(as, xmlValue, "//a")
link.text<-unlist(link.text.raw)
#Get Link Description
#link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc.text<-sapply(link.desc, xmlValue)
link.desc.text<-unlist(link.desc.text)
dftest<-data.frame(link, link.text, link.desc.text, stringsAsFactors = FALSE)
write.csv(dftest, file=SaveFileAs)
length(link)
length(link.desc.text)
length(link.text)
link[19]
#PURPOSE: Scrape the links and link descriptions from the old Map & GIS LibGuide
# http://guides.lib.ucdavis.edu/Maps_GIS
# Reference: http://dsi.ucdavis.edu/ClimateRefuge/
# Reference: http://datascience.ucdavis.edu/NSFWorkshops/WebScraping/ScheduleOutline.html
# Regex Builder: http://regexr.com/
#Load Libraries
library(XML)
library(RCurl)
#Where to save the CSV of links and what to call it
#SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\Links.csv"
SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\MapsOnline.csv"
#The target website
#LibGuide = "http://guides.lib.ucdavis.edu/Maps_GIS"
LibGuide = "http://guides.lib.ucdavis.edu/Maps_Online"
#Download website to a file
#getHTMLLinks(LibGuide)
raw.html<-htmlTreeParse(LibGuide, useInternalNodes=T)
#Parse HTML
#Stuff that didn't work:
#link.text<-xpathSApply(raw.html, "//a", xmlValue)
#uls<-xpathSApply(raw.html, "//li", xmlValue)
#uls<-getNodeSet(raw.html, "//li|//a/@href")
#Get the nodes that are unordered list items <li>
#lis<-getNodeSet(raw.html, "//li")
lis<-getNodeSet(raw.html, "//div[@class='linkdesc']//..")
#Get Links
#as<-getNodeSet(lis[[1]], "//a")
as<-getNodeSet(raw.html, "//div[@class='linkdesc']//..//a")
#as<-sapply(lis, getNodeSet, "//a")
link.raw<-sapply(as, xmlGetAttr, "href")
link<-unlist(link.raw)
#Get Link Text
link.text.raw<-sapply(as, xmlValue, "//a")
link.text<-unlist(link.text.raw)
#Get Link Description
#link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc<-getNodeSet(raw.html, "//div[@class='linkdesc']")
link.desc.text<-sapply(link.desc, xmlValue)
link.desc.text<-unlist(link.desc.text)
dftest<-data.frame(link[-19], link.text[-19], link.desc.text, stringsAsFactors = FALSE)
write.csv(dftest, file=SaveFileAs)
write.csv(dftest, file=SaveFileAs)
website<-"http://lib.ucdavis.edu"
htmlLink<-paste('<a href="', website, '"/a>')
htmlLink
htmlLink<-paste('<a href="', website, '"/a>', sep="")
htmlLink<-paste('<a href="', website, '"/a>', sep="")
htmlLink
website
x<-'"'
x
htmlLink<-paste('<a href=\"', website, '"/a>', sep="")
htmlLink
htmlLink<-paste('<a href="', website, '"/a>', sep="")
htmlLink
website<-"http://lib.ucdavis.edu"
linkText<-"Library"
htmlLink<-paste('<a href="', website, '>', linkText, '"</a>', sep="")
htmlLink
htmlLink<-paste('<a href="', website, '">', linkText, '</a>', sep="")
htmlLink
cat(htmlLink)
readFile<-"C:\\Users\\mmtobias\\Documents\\Website\\DataLinks.csv"
savedLinks<-read.csv(readFile, stringsAsFactors = FALSE)
head(savedLinks)
website<-savedLinks$link
#linkText<-"Library"
linkText<-savedLinks$link.text
htmlLink<-paste('<a href="', website, '">', linkText, '</a>', sep="")
htmlLink
data.frame(savedLinks, htmlLink)
newData<-data.frame(savedLinks, htmlLink)
names(newData)
SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\LinksHTML.csv"
write.csv(newData, SaveFileAs)
website<-savedLinks$link
#linkText<-"Library"
linkText<-savedLinks$link.text
linkDescr<-savedLinks$link.desc
htmlLink<-paste('<tr><td><a href="', website, '">', linkText, '</a></td><td>', linkDescr, '</td>,</tr>', sep="")
htmlLink
htmlLink<-paste('<tr><td><a href="', website, '">', linkText, '</a></td><td>', linkDescr, '</td></tr>', sep="")
htmlLink[50]
write.csv(htmlLink, SaveFileAs)
savedLinks<-savedLinks[-1:7]
savedLinks[1:7,]
savedLinks<-savedLinks[-1:7,]
savedLinks<-savedLinks[-8:191,]
savedLinks<-savedLinks[8:191,]
savedLinks[1]
savedLinks[1,]
savedLinks[length(savedLinks),]
dim(savedLinks)
savedLinks[184,]
readFile<-"C:\\Users\\mmtobias\\Documents\\Website\\MapsOnline.csv"
cartLinks<-read.csv(readFile, stringsAsFactors = FALSE)
cartLinks<-cartLinks[8:39,]
readFile<-"C:\\Users\\mmtobias\\Documents\\Website\\MapsOnline.csv"
cartLinks<-read.csv(readFile, stringsAsFactors = FALSE)
cartLinks<-cartLinks[8:39,]
mapWebsite<-savedLinks$link
cartWebsite<-cartLinks$link
website<-append(mapWebsite, cartWebsite)
website
#Load Data from Data Page
readFile<-"C:\\Users\\mmtobias\\Documents\\Website\\DataLinks.csv"
savedLinks<-read.csv(readFile, stringsAsFactors = FALSE)
savedLinks<-savedLinks[8:191,]
#Load Data from Cartography Page
readFile<-"C:\\Users\\mmtobias\\Documents\\Website\\MapsOnline.csv"
cartLinks<-read.csv(readFile, stringsAsFactors = FALSE)
cartLinks<-cartLinks[8:39,]
mapWebsite<-savedLinks$link
cartWebsite<-cartLinks$link
website<-append(mapWebsite, cartWebsite)
mapText<-savedLinks$link.text
cartText<-cartLinks$link.text
linkText<-append(mapText, cartText)
mapDescr<-savedLinks$link.desc
cartDescr<-cartLinks$link.desc
linkDescr<-append(mapDescr, cartDescr)
htmlLink<-paste('<tr><td><a href="', website, '">', linkText, '</a></td><td>', linkDescr, '</td></tr>', sep="")
SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\LinksHTML.csv"
write.csv(htmlLink, SaveFileAs)
x<-data.frame(website, linkText, linkDescr)
x<-x[order(linkText),]
head(x)
htmlLink<-paste('<tr><td><a href="', x$website, '">', x$linkText, '</a></td><td>', x$linkDescr, '</td></tr>', sep="")
SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\LinksHTML.csv"
write.csv(htmlLink, SaveFileAs)
write.csv(htmlLink, SaveFileAs)
library(devtools)
install.packages("devtools")
library(devtools)
?install_github()
install_github(ropensci/tabulizer)
install_github("ropensci/tabulizer")
library(tabulizer)
install.packages("pdftables")
library(pdftables)
?convert_pdf
avapdf<-"C:\\Users\\mmtobias\\Documents\\WineData\\AVAs_for_California_-_Copyright_2016_Wine_Institute_3.21.16.pdf"
avacsv<-"C:\\Users\\mmtobias\\Documents\\WineData\\avalist.csv"
convert_pdf(avapdf, output_file = avacsv)
avapdf<-"C:\\Users\\mmtobias\\Documents\\WineData\\AVAs_for_California_-_Copyright_2016_Wine_Institute_3.21.16.pdf"
avacsv<-"C:\\Users\\mmtobias\\Documents\\WineData\\avalist.csv"
convert_pdf(avapdf, output_file = avacsv)
install.packages("pdftools")
library(pdftools)
txt<-pdf_text(avapdf)
txt
str(txt)
txt[1]
install.packages("rJava")
install_github("ropensci/tabulizer")
install_github("ropensci/tabulizerjars")
#Load Data from Data Page
readFile<-"C:\\Users\\mmtobias\\Documents\\Website\\DataLinks.csv"
savedLinks<-read.csv(readFile, stringsAsFactors = FALSE)
savedLinks<-savedLinks[8:191,]
#Load Data from Cartography Page
readFile<-"C:\\Users\\mmtobias\\Documents\\Website\\MapsOnline.csv"
cartLinks<-read.csv(readFile, stringsAsFactors = FALSE)
cartLinks<-cartLinks[8:39,]
mapWebsite<-savedLinks$link
cartWebsite<-cartLinks$link
website<-append(mapWebsite, cartWebsite)
mapText<-savedLinks$link.text
cartText<-cartLinks$link.text
linkText<-append(mapText, cartText)
mapDescr<-savedLinks$link.desc
cartDescr<-cartLinks$link.desc
linkDescr<-append(mapDescr, cartDescr)
x<-data.frame(website, linkText, linkDescr)
x<-x[order(linkText),]
htmlLink<-paste('<tr><td><a href="', x$website, '">', x$linkText, '</a></td><td>', x$linkDescr, '</td></tr>', sep="")
head(htmlLink)
dim(htmlLink)
length(htmlLink)
norepeats<-unique(htmlLink)
length(norepeats)
htmlLink<-unique(htmlLink)
SaveFileAs <- "C:\\Users\\mmtobias\\Documents\\Website\\LinksHTML.csv"
write.csv(htmlLink, SaveFileAs)
# This R script combines all the GeoJSON files in a folder into one file, then writes it back to the folder.
# Modified from its original source: https://gist.github.com/wildintellect/582bb1096092170070996d21037b82d8
# TODO
# try reading each list and then combining them
library(raster)
library(geojsonio)
# probably want to change the pattern to exclude or filter after to drop the all.geojson file
avas <- list.files(path="./avas", pattern = "*json$", full.names = "TRUE")
tbd <- list.files(path="./tbd", pattern = "*json$", full.names = "TRUE")
gj <- c(avas, tbd)
# exclude the all.geojson file... probably a more elegant way to do this, but this works:
gj <- gj[gj != "./avas.geojson"]
#read all the geojson files with readOGR? or geojsonio package
vects <- lapply(gj, geojson_read, what="sp")
#combine all the vectors together, bind is from the raster package
#probably could just rbind geojson lists too, but thats harder to plot
all <- do.call(bind, vects)
geojson_write(all, file="all.geojson", overwrite=TRUE, convert_wgs84 = TRUE)
# tested 3/30/2017 with 2 geojson polygons -> success -- MicheleTobias
something<- lapply(tbd, geojson_read, what="sp")
something
tbd
avas
setwd("C:\\Users\\mmtobias\\Documents\\GitHub\\ava")
avas <- list.files(path="./avas", pattern = "*json$", full.names = "TRUE")
tbd <- list.files(path="./tbd", pattern = "*json$", full.names = "TRUE")
tbd
gj <- c(avas, tbd)
gj <- gj[gj != "./avas.geojson"]
vects <- lapply(gj, geojson_read, what="sp")
vects
testgj<-lint(gj)
? apply
testgj<-apply(gj, fun=lint)
testgj<-apply(gj, FUN=lint)
dim(gj)
gj <- c(avas, tbd)
dim(gj)
avas <- list.files(path="./avas", pattern = "*json$", full.names = "TRUE")
tbd <- list.files(path="./tbd", pattern = "*json$", full.names = "TRUE")
gj <- c(avas, tbd)
dim(gj)
length(gj)
?lapply
testgj<-lapply(gj, FUN=lint)
testgj<-lapply(avas, FUN=lint)
avavects  <- lapply(avas, geojson_read, what="sp")
tbdvects  <- lapply(tbd, geojson_read, what="sp")
dim(avavects)
length(avavects)
length(tbdvects)
tbdvects  <- lapply(tbd[1], geojson_read, what="sp")
tbdvects
? try
try(lapply(tbd[1], geojson_read, what="sp"))
try(lapply(tbd[2], geojson_read, what="sp"))
?lapply
for
tbdvects  <- c()
for (i in tbd){
tbdi <- geojson_read(i, method="sp")
tbdvects <- c(tbdvects, tbdi)
print(i)
}
tbdvects  <- c()
for (i in tbd){
tbdi <- geojson_read(i)
tbdvects <- c(tbdvects, tbdi)
print(i)
}
length(tbdvects)
length(gj)
vects  <- c()
for (i in gj){
tbdi <- geojson_read(i)
vects <- c(vects, tbdi)
print(i)
}
all <- do.call(bind, vects)
length(vects)
vects
all <- do.call(bind, vects)
geojson_write(all, file="all.geojson", overwrite=TRUE, convert_wgs84 = TRUE)
str(vects)
length(vects[2])
length(vects[3])
str(vects[2])
for (i in gj){
tbdlint <- lint(geojson_read(i))
#vects <- c(vects, tbdi)
print(tbdlint)
}
for (i in gj){
tbdi <- geojson_read(i)
tbdlint<-lint(tbdi)
#vects <- c(vects, tbdi)
print(tbdlint)
}
geojson_read(gj[1])
lint(geojson_read(gj[1]))
for (i in gj){
tbdi <- geojson_read(i)
#tbdlint<-lint(tbdi)
vects <- c(vects, tbdi)
#print(tbdlint)
}
all <- do.call(bind, vects)
readOGR(gj[1])
install.packages("rgdal")
